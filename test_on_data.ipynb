{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic import data to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "start reading\ndone separate x and y\n"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# import data\n",
    "print('start reading')\n",
    "f = open(\"TraData.csv\")\n",
    "data = np.loadtxt(f, delimiter=',')\n",
    "\n",
    "# select data\n",
    "x = data[:, 1:]  # select columns 1 through end\n",
    "y = data[:, 0]   # select column 0, the result\n",
    "print('done separate x and y')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocess\n",
    "- first normalize data and scaling \n",
    "- then select 95 % important thing out of the data \n",
    "    - select percentile\n",
    "- Use PCA to take data\n",
    "- disjoint training and validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(500000, 31)\n(500000, 29)\n(500000, 29)\nstart2\n"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "from scipy.stats import pearsonr\n",
    "import numpy as np\n",
    "\n",
    "normalizer = preprocessing.Normalizer().fit(x)\n",
    "X_scaled = preprocessing.RobustScaler().fit(x)\n",
    "normalizer.transform(x)\n",
    "X_scaled.transform(x)\n",
    "print(x.shape)\n",
    "\n",
    "X_new = SelectPercentile(percentile=95).fit_transform(x, y)\n",
    "print(X_new.shape)\n",
    "\n",
    "pca = PCA(n_components=29)\n",
    "X_pca = pca.fit_transform(X_new)\n",
    "print(X_pca.shape)\n",
    "# print(pca.explained_variance_ratio_)\n",
    "\n",
    "train_x, valid_x,train_y,valid_y = train_test_split(X_pca,y,test_size=0.1)\n",
    "print('start2')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "start random forest\nTraining Acc:\n 0.5645955555555555\nTraining data predict:\n [1. 1. 1. ... 0. 1. 1.]\nValidate Accuracy:\n 0.56436\nValidate data predict:\n [0. 1. 1. ... 1. 0. 1.]\n"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "print('start random forest')\n",
    "# random forest\n",
    "clf2 = RandomForestClassifier(criterion='entropy',max_samples = 10,\n",
    "                                  n_estimators=30)\n",
    "clf2 = clf2.fit(train_x,train_y)\n",
    "\n",
    "print('Training Acc:\\n',clf2.score(train_x,train_y))\n",
    "print('Training data predict:\\n',clf2.predict(train_x))\n",
    "print('Validate Accuracy:\\n',clf2.score(valid_x,valid_y))\n",
    "print('Validate data predict:\\n',clf2.predict(valid_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neuro network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "start neuro network\n"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf4 = MLPClassifier(activation='relu',solver='sgd',max_iter=2000,learning_rate_init=0.001,\n",
    "                    hidden_layer_sizes=(45,35)) \n",
    "print('start neuro network')\n",
    "clf4 = clf4.fit(train_x,train_y)\n",
    "print('Training Acc:\\n',clf4.score(train_x,train_y))\n",
    "print('Training data predict:\\n',clf4.predict(train_x))\n",
    "print('Validate Accuracy:\\n',clf4.score(valid_x,valid_y))\n",
    "print('Validate data predict:\\n',clf4.predict(valid_x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}